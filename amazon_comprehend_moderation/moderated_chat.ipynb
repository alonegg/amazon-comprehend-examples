{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a88b9bd-d587-4760-94dc-ea7219a5ca61",
   "metadata": {},
   "source": [
    "# Moderated Chat application samples with `AmazonComprehendModerationChain`\n",
    "---\n",
    "\n",
    "Install the necessary libraries. We use [Gradio](https://www.gradio.app/) for the Chat UI interface.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> You must use a Python3 kernel to run this notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d098bf-b48b-4e5f-9d73-44eb5ec276cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U gradio boto3 nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34050a-147e-43c7-8bfd-d329f219d82c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain_experimental huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f5e2a-fb42-45f7-b49a-bff43c954415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain pydantic --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc5061-cf07-4cef-91f6-008436011ce0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sample moderated chatbot with Amazon Bedrock\n",
    "---\n",
    "\n",
    "You can use the sample prompt below to start testing the chatbot:\n",
    "\n",
    "```\n",
    "What is John Doe's address, phone number and SSN from the following text?\n",
    "\n",
    "John Doe, a resident of 1234 Elm Street in Springfield, recently celebrated his birthday on January 1st. Turning 43 this year, John reflected on the years gone by. He often shares memories of his younger days with his close friends through calls on his phone, (555) 123-4567. Meanwhile, during a casual evening, he received an email at johndoe@example.com reminding him of an old acquaintance's reunion. As he navigated through some old documents, he stumbled upon a paper that listed his SSN as 123-45-6789, reminding him to store it in a safer place.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0babe13-3316-49c5-af0b-7f9e4b982efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "comprehend_client = boto3.client('comprehend', region_name='us-east-1')\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "model_id = \"<your-model-id>\"\n",
    "model_id=\"anthropic.claude-instant-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadcc7d-a9bf-4831-858e-4a33b21a2154",
   "metadata": {},
   "source": [
    "Get your API Key from Huggingface hub - https://huggingface.co/docs/api-inference/quicktour#get-your-api-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b64d5-4743-4d00-8850-89e84b88e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.comprehend_moderation import (AmazonComprehendModerationChain,                                                          \n",
    "                                                         BaseModerationConfig, \n",
    "                                                         ModerationPromptSafetyConfig, \n",
    "                                                         ModerationPiiConfig, \n",
    "                                                         ModerationToxicityConfig)\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "\n",
    "config_filter = {\"PII\": ModerationPiiConfig(threshold=0.5, labels=[\"SSN\", \"CREDIT_DEBIT_NUMBER\"], mask_character=\"X\", redact=True), \n",
    "                 \"Toxicity\": None, \n",
    "                 \"Prompt-safety\": None}\n",
    "\n",
    "def respond(message, chat_history):    \n",
    "    template = \"\\n\\nHuman:{question}\\n\\nAssistant:\"\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    bedrock_llm = Bedrock(client=bedrock, model_id=model_id, model_kwargs={'temperature':0, \"stop_sequences\": [\"\\n\\nHuman:\",\"</answer>\"]})\n",
    "    \n",
    "    filters = [value for value in config_filter.values() if value is not None]\n",
    "    # define different moderation configs using the filter configs above\n",
    "    mod_config = BaseModerationConfig(filters=filters)\n",
    "    \n",
    "    mod_config = BaseModerationConfig(filters=filters) if filters else BaseModerationConfig()\n",
    "    comprehend_moderation = AmazonComprehendModerationChain(client=comprehend_client, \n",
    "                                                            moderation_config = mod_config,\n",
    "                                                            verbose=False)\n",
    "\n",
    "    try:\n",
    "        chain = (prompt \n",
    "                 | comprehend_moderation \n",
    "                 | {\"input\": (lambda x: x['output'] ) | bedrock_llm}\n",
    "                 | comprehend_moderation \n",
    "                )\n",
    "        response = chain.invoke({\"question\": message})\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        error_msg = f\"<b style='color:red;'>Error: {str(e)}</b>\"\n",
    "        return error_msg\n",
    "\n",
    "def on_select(evt: gr.SelectData):\n",
    "    if evt.target.label == \"PII\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationPiiConfig(threshold=0.5, labels=[\"SSN\", \"CREDIT_DEBIT_NUMBER\"], mask_character=\"X\", redact=True)\n",
    "    elif evt.target.label == \"Toxicity\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationToxicityConfig(threshold=0.6)\n",
    "    elif evt.target.label == \"Prompt-safety\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationPromptSafetyConfig(threshold=0.8)\n",
    "    return f\"You selected {evt.value} at {evt.index} from {evt.target} and selection is {evt.selected}\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.ChatInterface(respond)\n",
    "        with gr.Column(scale=0):\n",
    "            pii = gr.Checkbox(label=\"PII\", value=True, interactive=True) \n",
    "            pii.select(on_select)\n",
    "            tox = gr.Checkbox(label=\"Toxicity\", value=False, interactive=True)                \n",
    "            tox.select(on_select)\n",
    "            intent = gr.Checkbox(label=\"Prompt-safety\", value=False, interactive=True)                \n",
    "            intent.select(on_select)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb731a-9ea7-41e6-91d3-16c0e98447da",
   "metadata": {},
   "source": [
    "## Sample moderated chatbot with Hugging Face Hub model\n",
    "---\n",
    "\n",
    "You can use the sample prompt below to start testing the chatbot:\n",
    "\n",
    "```\n",
    "What is John Doe's address, phone number and SSN from the following text?\n",
    "\n",
    "John Doe, a resident of 1234 Elm Street in Springfield, recently celebrated his birthday on January 1st. Turning 43 this year, John reflected on the years gone by. He often shares memories of his younger days with his close friends through calls on his phone, (555) 123-4567. Meanwhile, during a casual evening, he received an email at johndoe@example.com reminding him of an old acquaintance's reunion. As he navigated through some old documents, he stumbled upon a paper that listed his SSN as 123-45-6789, reminding him to store it in a safer place.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0bbec-9e07-486c-b890-d4cbd902bd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "comprehend_client = boto3.client('comprehend', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d49341-d7b6-4361-98fc-ebe3db105d3f",
   "metadata": {},
   "source": [
    "Get your API Key from Huggingface hub - https://huggingface.co/docs/api-inference/quicktour#get-your-api-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826793e-ba8b-448b-a96c-7295185cc346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df19cd4-2419-4321-9994-70e44f12939e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f9a2f-44bc-4a37-83ed-16ecc466e1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_experimental.comprehend_moderation import (AmazonComprehendModerationChain,                                                          \n",
    "                                                         BaseModerationConfig, \n",
    "                                                         ModerationPromptSafetyConfig, \n",
    "                                                         ModerationPiiConfig, \n",
    "                                                         ModerationToxicityConfig)\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "\n",
    "config_filter = {\"PII\": ModerationPiiConfig(threshold=0.5, labels=[\"SSN\", \"CREDIT_DEBIT_NUMBER\"], mask_character=\"X\", redact=True), \n",
    "                 \"Toxicity\": None, \n",
    "                 \"Prompt-safety\": None}\n",
    "\n",
    "def respond(message, chat_history):    \n",
    "    repo_id = \"google/flan-t5-xxl\" # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "\n",
    "    template = \"\"\"Question: {question}\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 256}\n",
    "    )\n",
    "    \n",
    "    filters = [value for value in config_filter.values() if value is not None]\n",
    "    # define different moderation configs using the filter configs above\n",
    "    mod_config = BaseModerationConfig(filters=filters)\n",
    "    \n",
    "    mod_config = BaseModerationConfig(filters=filters) if filters else BaseModerationConfig()\n",
    "    comprehend_moderation = AmazonComprehendModerationChain(client=comprehend_client, \n",
    "                                                            moderation_config = mod_config,\n",
    "                                                            verbose=False)\n",
    "\n",
    "    try:\n",
    "        chain = (prompt \n",
    "                 | comprehend_moderation \n",
    "                 | {\"input\": (lambda x: x['output'] ) | llm}\n",
    "                 | comprehend_moderation \n",
    "                )\n",
    "        response = chain.invoke({\"question\": message})\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        error_msg = f\"<b style='color:red;'>Error: {str(e)}</b>\"\n",
    "        return error_msg\n",
    "\n",
    "def on_select(evt: gr.SelectData):\n",
    "    if evt.target.label == \"PII\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationPiiConfig(threshold=0.5, labels=[\"SSN\", \"CREDIT_DEBIT_NUMBER\"], mask_character=\"X\", redact=True)\n",
    "    elif evt.target.label == \"Toxicity\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationToxicityConfig(threshold=0.6)\n",
    "    elif evt.target.label == \"Prompt-safety\":\n",
    "        config_filter[evt.target.label] = None if not evt.value else ModerationPromptSafetyConfig(threshold=0.8)\n",
    "    return f\"You selected {evt.value} at {evt.index} from {evt.target} and selection is {evt.selected}\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.ChatInterface(respond)\n",
    "        with gr.Column(scale=0):\n",
    "            pii = gr.Checkbox(label=\"PII\", value=True, interactive=True) \n",
    "            pii.select(on_select)\n",
    "            tox = gr.Checkbox(label=\"Toxicity\", value=False, interactive=True)                \n",
    "            tox.select(on_select)\n",
    "            intent = gr.Checkbox(label=\"Prompt-safety\", value=False, interactive=True)                \n",
    "            intent.select(on_select)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a90321-bc1b-4576-8bc4-6c0a0412d881",
   "metadata": {},
   "source": [
    "#### Troubleshooting\n",
    "---\n",
    "\n",
    "If you receive the following error\n",
    "\n",
    "```\n",
    "'Comprehend' object has no attribute 'detect_toxic_content'\n",
    "```\n",
    "\n",
    "this means that your Boto3 is out of date, if you have installed the updates already then please restart the notebook kernel using the controls above or by running the following piece of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675f886-4159-495d-a4d0-a282876f4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482a359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
